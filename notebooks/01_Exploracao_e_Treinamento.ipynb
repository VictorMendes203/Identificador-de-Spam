{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c952e17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dados Carregados ---\n",
      "                                                text  spam\n",
      "0  Subject: naturally irresistible your corporate...     1\n",
      "1  Subject: the stock trading gunslinger  fanny i...     1\n",
      "2  Subject: unbelievable new homes made easy  im ...     1\n",
      "3  Subject: 4 color printing special  request add...     1\n",
      "4  Subject: do not have money , get software cds ...     1\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5728 entries, 0 to 5727\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5728 non-null   object\n",
      " 1   spam    5728 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 89.6+ KB\n",
      "None\n",
      "\n",
      "\n",
      "Total de e-mails: 5728\n",
      "Total de classes (y): 5728\n",
      "\n",
      "\n",
      "--- Bag of Words (BoW) Aplicado ---\n",
      "Formato da matriz BoW: (5728, 37303)\n",
      "\n",
      "\n",
      "--- Dados Prontos para Treinamento ---\n",
      "Tamanho do set de Treino (X): (4582, 37303)\n",
      "Tamanho do set de Teste (X): (1146, 37303)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# --- 1. Carregar os Dados ---\n",
    "# Usamos '..' para \"voltar\" uma pasta (de 'notebooks' para 'Detector de Spam')\n",
    "# e depois entrar na pasta 'data/'\n",
    "filepath = '../data/emails.csv'\n",
    "\n",
    "# Tentar carregar com encoding 'utf-8', se der erro, tentar 'latin-1'\n",
    "try:\n",
    "    df = pd.read_csv(filepath, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(filepath, encoding='latin-1')\n",
    "\n",
    "print(\"--- Dados Carregados ---\")\n",
    "print(df.head()) # Mostra as 5 primeiras linhas\n",
    "print(\"\\n\")\n",
    "print(df.info()) # Resumo do dataset\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# --- 2. Preparar os Dados para o Modelo ---\n",
    "# O 'X' (features) Ã© o texto do e-mail.\n",
    "# O 'y' (target) Ã© a coluna que diz se Ã© spam (1) ou nÃ£o (0).\n",
    "X = df['text']\n",
    "y = df['spam']\n",
    "\n",
    "print(f\"Total de e-mails: {len(X)}\")\n",
    "print(f\"Total de classes (y): {len(y)}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# --- 3. Aplicar a TÃ©cnica \"Bag of Words\" ---\n",
    "# 1. Instanciar o 'vetorizador'. CountVectorizer Ã© a ferramenta do scikit-learn\n",
    "#    que implementa o Bag of Words.\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# 2. 'fit_transform':\n",
    "#    - 'fit': Aprende todo o vocabulÃ¡rio (todas as palavras Ãºnicas) do seu 'X'.\n",
    "#    - 'transform': Transforma cada e-mail em um vetor (uma linha)\n",
    "#      onde cada coluna Ã© a contagem de uma palavra do vocabulÃ¡rio.\n",
    "X_bow = vectorizer.fit_transform(X)\n",
    "\n",
    "print(\"--- Bag of Words (BoW) Aplicado ---\")\n",
    "# O resultado Ã© uma \"matriz esparsa\"\n",
    "# (NÂº de E-mails, NÂº de Palavras Ãšnicas no VocabulÃ¡rio)\n",
    "print(f\"Formato da matriz BoW: {X_bow.shape}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# --- 4. Dividir em Treino e Teste ---\n",
    "# Vamos usar 80% dos dados para treinar o modelo e 20% para testar\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_bow,  # Nossos e-mails jÃ¡ vetorizados\n",
    "    y,      # Nossas classes (spam ou nÃ£o)\n",
    "    test_size=0.20, # 20% para teste\n",
    "    random_state=42 # 'random_state' garante que a divisÃ£o seja sempre a mesma\n",
    ")\n",
    "\n",
    "print(\"--- Dados Prontos para Treinamento ---\")\n",
    "print(f\"Tamanho do set de Treino (X): {X_train.shape}\")\n",
    "print(f\"Tamanho do set de Teste (X): {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e04053b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Treinando Naive Bayes ---\n",
      "AcurÃ¡cia do Naive Bayes: 99.13%\n",
      "\n",
      "RelatÃ³rio de ClassificaÃ§Ã£o (Naive Bayes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ham (0)       1.00      0.99      0.99       856\n",
      "    Spam (1)       0.97      0.99      0.98       290\n",
      "\n",
      "    accuracy                           0.99      1146\n",
      "   macro avg       0.99      0.99      0.99      1146\n",
      "weighted avg       0.99      0.99      0.99      1146\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "--- Treinando SVM (LinearSVC) ---\n",
      "AcurÃ¡cia do SVM: 98.60%\n",
      "\n",
      "RelatÃ³rio de ClassificaÃ§Ã£o (SVM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ham (0)       0.98      1.00      0.99       856\n",
      "    Spam (1)       0.99      0.96      0.97       290\n",
      "\n",
      "    accuracy                           0.99      1146\n",
      "   macro avg       0.99      0.98      0.98      1146\n",
      "weighted avg       0.99      0.99      0.99      1146\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# --- 5. Treinar o Classificador: Naive Bayes ---\n",
    "# MultinomialNB Ã© o classificador Naive Bayes clÃ¡ssico para contagem de palavras (Bag of Words)\n",
    "print(\"--- Treinando Naive Bayes ---\")\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsÃµes no set de TESTE\n",
    "y_pred_nb = nb_classifier.predict(X_test)\n",
    "\n",
    "# --- 6. Avaliar o Naive Bayes ---\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(f\"AcurÃ¡cia do Naive Bayes: {accuracy_nb * 100:.2f}%\")\n",
    "print(\"\\nRelatÃ³rio de ClassificaÃ§Ã£o (Naive Bayes):\")\n",
    "# Mostra precisÃ£o, recall e F1-score\n",
    "print(classification_report(y_test, y_pred_nb, target_names=['Ham (0)', 'Spam (1)']))\n",
    "print(\"-\" * 40 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- 7. Treinar o Classificador: SVM (Support Vector Machine) ---\n",
    "# Usamos LinearSVC, que Ã© uma implementaÃ§Ã£o de SVM otimizada para texto (muito mais rÃ¡pida)\n",
    "print(\"--- Treinando SVM (LinearSVC) ---\")\n",
    "svm_classifier = LinearSVC(max_iter=5000)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsÃµes no set de TESTE\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "# --- 8. Avaliar o SVM ---\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"AcurÃ¡cia do SVM: {accuracy_svm * 100:.2f}%\")\n",
    "print(\"\\nRelatÃ³rio de ClassificaÃ§Ã£o (SVM):\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=['Ham (0)', 'Spam (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b921ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Naive Bayes salvo em: ../models\\spam_model.pkl\n",
      "Vetorizador Bag of Words salvo em: ../models\\vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# --- 9. Salvar os artefatos do Modelo ---\n",
    "\n",
    "# Definir o caminho da pasta de modelos\n",
    "model_dir = '../models'\n",
    "# Definir os caminhos dos arquivos\n",
    "model_path = os.path.join(model_dir, 'spam_model.pkl')\n",
    "vectorizer_path = os.path.join(model_dir, 'vectorizer.pkl')\n",
    "\n",
    "# Criar a pasta 'models' se ela nÃ£o existir\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# 1. Salvar o ðŸ§  (O Classificador Naive Bayes)\n",
    "# Este Ã© o 'cÃ©rebro' que aprendeu a diferenciar spam de ham\n",
    "joblib.dump(nb_classifier, model_path)\n",
    "print(f\"Modelo Naive Bayes salvo em: {model_path}\")\n",
    "\n",
    "# 2. Salvar o ðŸ“– (O Vetorizador Bag of Words)\n",
    "# Este Ã© o 'dicionÃ¡rio' que transforma texto em nÃºmeros.\n",
    "# ESTE Ã‰ O ARQUIVO MAIS IMPORTANTE!\n",
    "joblib.dump(vectorizer, vectorizer_path)\n",
    "print(f\"Vetorizador Bag of Words salvo em: {vectorizer_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e919f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modelo e Vetorizador carregados com sucesso!\n",
      "\n",
      "--- Testing 'Ham' Email ---\n",
      "Result: 0 (Classified as HAM) -> CORRECT!\n",
      "\n",
      "--- Testing 'Spam' Email ---\n",
      "Result: 1 (Classified as SPAM) -> CORRECT!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# --- 10. Carregar Modelo e Vetorizador Salvos ---\n",
    "# (Vamos carregar de novo para ter certeza)\n",
    "model_path = '../models/spam_model.pkl'\n",
    "vectorizer_path = '../models/vectorizer.pkl'\n",
    "\n",
    "loaded_model = joblib.load(model_path)\n",
    "loaded_vectorizer = joblib.load(vectorizer_path)\n",
    "\n",
    "print(\"âœ… Modelo e Vetorizador carregados com sucesso!\")\n",
    "\n",
    "# --- 11. Simular Novos E-mails (AGORA EM INGLÃŠS) ---\n",
    "\n",
    "# E-mail de teste \"Ham\" (NÃ£o-Spam)\n",
    "email_teste_ham = [\n",
    "    \"Subject: Hi team, quick update on the project. Please see the attached slides for tomorrow's meeting. Thanks.\"\n",
    "]\n",
    "\n",
    "# E-mail de teste \"Spam\"\n",
    "email_teste_spam = [\n",
    "    \"Subject: Congratulations! You won a $1,000,000 lottery prize! Click here to claim your reward NOW. Limited time offer!\"\n",
    "]\n",
    "\n",
    "\n",
    "# --- 12. Fazer a PrevisÃ£o ---\n",
    "\n",
    "print(\"\\n--- Testing 'Ham' Email ---\")\n",
    "# 1. Transformar o texto 'ham'\n",
    "ham_bow = loaded_vectorizer.transform(email_teste_ham)\n",
    "# 2. Fazer a previsÃ£o\n",
    "prediction_ham = loaded_model.predict(ham_bow)\n",
    "# 3. Mostrar o resultado\n",
    "if prediction_ham[0] == 0:\n",
    "    print(\"Result: 0 (Classified as HAM) -> CORRECT!\")\n",
    "else:\n",
    "    print(\"Result: 1 (Classified as SPAM) -> INCORRECT!\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Testing 'Spam' Email ---\")\n",
    "# 1. Transformar o texto 'spam'\n",
    "spam_bow = loaded_vectorizer.transform(email_teste_spam)\n",
    "# 2. Fazer a previsÃ£o\n",
    "prediction_spam = loaded_model.predict(spam_bow)\n",
    "# 3. Mostrar o resultado\n",
    "if prediction_spam[0] == 1:\n",
    "    print(\"Result: 1 (Classified as SPAM) -> CORRECT!\")\n",
    "else:\n",
    "    print(\"Result: 0 (Classified as HAM) -> INCORRECT!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
